{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Загрузим данные, приведем их к числовым, заполним пропуски, нормализуем данные и оптимизируем память.\n",
    "\n",
    "Разделим выборку на обучающую/проверочную в соотношении 80/20.\n",
    "\n",
    "Построим 4 модели логистической регрессии: для 8, 6 и остальных классов, для 2, 5 и остальных, для 1, 7 и остальных, и для 4 и 3 - по убыванию частоты значения. Будем использовать перекрестную проверку при принятии решения об оптимальном наборе столбцов.\n",
    "\n",
    "Проведем предсказание и проверим качество через каппа-метрику.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/prudential/train.csv.gz\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/prudential-life-insurance-assessment/\n",
    "\n",
    "© ITtensive, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 128 entries, Id to Response\n",
      "dtypes: float64(18), int64(109), object(1)\n",
      "memory usage: 58.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://video.ittensive.com/machine-learning/prudential/train.csv.gz\")\n",
    "print (data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Product_Info_2_1\"] = data[\"Product_Info_2\"].str.slice(0, 1)\n",
    "data[\"Product_Info_2_2\"] = pd.to_numeric(data[\"Product_Info_2\"].str.slice(1, 2))\n",
    "data.drop(labels=[\"Product_Info_2\"], axis=1, inplace=True)\n",
    "for l in data[\"Product_Info_2_1\"].unique():\n",
    "    data[\"Product_Info_2_1\" + l] = data[\"Product_Info_2_1\"].isin([l]).astype(\"int8\")\n",
    "data.drop(labels=[\"Product_Info_2_1\"], axis=1, inplace=True)\n",
    "data.fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage (df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if str(col_type)[:5] == \"float\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo(\"f2\").min and c_max < np.finfo(\"f2\").max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif c_min > np.finfo(\"f4\").min and c_max < np.finfo(\"f4\").max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "        elif str(col_type)[:3] == \"int\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo(\"i1\").min and c_max < np.iinfo(\"i1\").max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo(\"i2\").min and c_max < np.iinfo(\"i2\").max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo(\"i4\").min and c_max < np.iinfo(\"i4\").max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo(\"i8\").min and c_max < np.iinfo(\"i8\").max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Потребление памяти меньше на', round(start_mem - end_mem, 2), 'Мб (минус', round(100 * (start_mem - end_mem) / start_mem, 1), '%)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 49.49 Мб (минус 84.9 %)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 133 entries, Id to Product_Info_2_1B\n",
      "dtypes: float16(18), int16(1), int32(1), int8(113)\n",
      "memory usage: 8.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = reduce_mem_usage(data)\n",
    "print (data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий набор столбцов для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wt', 'Ht', 'Ins_Age', 'BMI', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_5', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', 'Medical_Keyword_1', 'Medical_Keyword_2', 'Medical_Keyword_3', 'Medical_Keyword_4', 'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7', 'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10', 'Medical_Keyword_11', 'Medical_Keyword_12', 'Medical_Keyword_13', 'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16', 'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19', 'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22', 'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25', 'Medical_Keyword_26', 'Medical_Keyword_27', 'Medical_Keyword_28', 'Medical_Keyword_29', 'Medical_Keyword_30', 'Medical_Keyword_31', 'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_34', 'Medical_Keyword_35', 'Medical_Keyword_36', 'Medical_Keyword_37', 'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40', 'Medical_Keyword_41', 'Medical_Keyword_42', 'Medical_Keyword_43', 'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46', 'Medical_Keyword_47', 'Medical_Keyword_48', 'Family_Hist_1', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5', 'Medical_History_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', 'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_15', 'Medical_History_16', 'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_24', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', 'Medical_History_31', 'Medical_History_32', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', 'Medical_History_40', 'Medical_History_41', 'Product_Info_1', 'Product_Info_3', 'Product_Info_4', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7', 'Product_Info_2_2', 'Product_Info_2_1D', 'Product_Info_2_1A', 'Product_Info_2_1E', 'Product_Info_2_1C', 'Product_Info_2_1B']\n"
     ]
    }
   ],
   "source": [
    "columns_groups = [\"Insurance_History\", \"InsurеdInfo\", \"Medical_Keyword\",\n",
    "                  \"Family_Hist\", \"Medical_History\", \"Product_Info\"]\n",
    "columns = [\"Wt\", \"Ht\", \"Ins_Age\", \"BMI\"]\n",
    "for cg in columns_groups:\n",
    "    columns.extend(data.columns[data.columns.str.startswith(cg)])\n",
    "print (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "data_transformed = pd.DataFrame(scaler.fit_transform(pd.DataFrame(data,\n",
    "                                                     columns=columns)))\n",
    "columns_transformed = data_transformed.columns\n",
    "data_transformed[\"Response\"] = data[\"Response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных\n",
    "Преобразуем выборки в отдельные наборы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "33363 -0.748444 -1.687657  0.820652  0.154055  0.611857 -0.169414 -1.159587   \n",
      "34204  0.612962  0.759700 -1.148525  0.281905  0.611857 -0.169414 -1.159587   \n",
      "41014 -0.866351 -0.707398 -1.299572 -0.660989  0.611857 -0.169414  0.862391   \n",
      "25660  1.600085  0.759700  0.289513  1.416575  0.611857 -0.169414  0.862391   \n",
      "34300  0.355214  0.759700  0.213990 -0.013748 -1.634368 -0.169414  0.862391   \n",
      "\n",
      "              7         8         9  ...       109       110       111  \\\n",
      "33363  1.101046 -1.156735  1.130555  ... -0.083689  0.441621 -0.149284   \n",
      "34204  1.101046 -1.156735  1.130555  ... -0.083689  0.441621 -0.149284   \n",
      "41014 -1.013721  0.861233 -0.928723  ... -0.083689  0.441621 -0.149284   \n",
      "25660 -1.013721  0.866008 -0.928723  ... -0.083689  0.441621 -0.149284   \n",
      "34300 -1.013721  0.864934 -0.928723  ... -0.083689  0.441621 -0.149284   \n",
      "\n",
      "            112       113       114       115       116       117  Response  \n",
      "33363 -0.200031  0.750845 -0.623305 -0.216001 -0.128866 -0.142142         7  \n",
      "34204  0.266799  0.750845 -0.623305 -0.216001 -0.128866 -0.142142         7  \n",
      "41014 -1.133690 -1.331832  1.604350 -0.216001 -0.128866 -0.142142         8  \n",
      "25660 -0.666860  0.750845 -0.623305 -0.216001 -0.128866 -0.142142         5  \n",
      "34300 -0.666860  0.750845 -0.623305 -0.216001 -0.128866 -0.142142         8  \n",
      "\n",
      "[5 rows x 119 columns]\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data_transformed,\n",
    "                                         test_size=0.2)\n",
    "data_train = pd.DataFrame(data_train)\n",
    "data_test = pd.DataFrame(data_test)\n",
    "print (data_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия\n",
    "В обучающих данных пометим все классы, кроме 6 и 8, как 0 - и проведем обучение по такому набору данных.\n",
    "\n",
    "Затем в оставшихся данных (в которых класс не равен 6 или 8) заменим все классы, кроме 7 и 1, на 0 - и снова проведем обучение. И т.д. Получим иерархию классификаторов:\n",
    "8/6/нет -> 7/1/нет -> 2/5/нет -> 4/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def regression_model (columns, df):\n",
    "    x = pd.DataFrame(df, columns=columns)\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(x, df[\"Response\"])\n",
    "    return model\n",
    "\n",
    "def logistic_regression(columns, df_train):\n",
    "    model = regression_model(columns, df_train)\n",
    "    logr_grid = GridSearchCV(model, {}, cv=5, n_jobs=2,\n",
    "                    scoring=make_scorer(cohen_kappa_score))\n",
    "    x = pd.DataFrame(df_train, columns=columns)\n",
    "    logr_grid.fit(x, df_train[\"Response\"])\n",
    "    return logr_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимальный набор столбцов\n",
    "Для каждого уровня иерархии это будет свой набор столбцов в исходных данных.\n",
    "\n",
    "### Перекрестная проверка\n",
    "Разбиваем обучающую выборку еще на k (часто 5) частей, на каждой части данных обучаем модель. Затем проверяем 1-ю, 2-ю, 3-ю, 4-ю части на 5; 1-ю, 2-ю, 3-ю, 5-ю части на 4 и т.д.\n",
    "\n",
    "В итоге обучение пройдет весь набор данных, и каждая часть набора будет проверена на всех оставшихся (перекрестным образом)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_opt_columns (data_train):\n",
    "    kappa_score_opt = 0\n",
    "    columns_opt = []\n",
    "    for col in columns_transformed:\n",
    "        kappa_score = logistic_regression([col], data_train)\n",
    "        if kappa_score > kappa_score_opt:\n",
    "            columns_opt = [col]\n",
    "            kappa_score_opt = kappa_score\n",
    "    for col in columns_transformed:\n",
    "        if col not in columns_opt:\n",
    "            columns_opt.append(col)\n",
    "            kappa_score = logistic_regression(columns_opt, data_train)\n",
    "            if kappa_score < kappa_score_opt:\n",
    "                columns_opt.pop()\n",
    "            else:\n",
    "                kappa_score_opt = kappa_score\n",
    "    return columns_opt, kappa_score_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем последовательно \"урезать\" набор данных при расчете более глубоких моделей: после получения разделения на 8 и остальные отсечем все данные со значением 8, и т.д.\n",
    "\n",
    "После каждого расчета модели будем вычислять значения в проверочной выборке. Проверочную выборку нулями заполнять не будем, иначе оценка будет считаться некорректно.\n",
    "\n",
    "Набор разделений 6/8, 2/5, 1/7, 3/4 дает наибольшую точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4177708439342368 [3, 0, 2, 4, 5, 6, 9, 10, 14, 15, 20, 22, 23, 24, 25, 26, 28, 31, 34, 35, 38, 43, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 68, 69, 73, 79, 81, 82, 83, 84, 85, 87, 88, 90, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 108, 109, 110, 111, 116, 117]\n",
      "1 0.1890318340814155 [14, 2, 3, 5, 6, 8, 9, 15, 17, 18, 19, 23, 25, 26, 27, 29, 32, 34, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 59, 60, 61, 65, 68, 69, 72, 73, 74, 75, 79, 80, 82, 83, 84, 86, 87, 88, 92, 93, 94, 100, 104, 107, 108, 109, 111, 112, 115, 117]\n",
      "2 0.533997292619593 [3, 1, 2, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 29, 31, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 59, 60, 61, 62, 64, 65, 66, 68, 69, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 99, 102, 103, 104, 105, 106, 108, 111, 113, 114, 116]\n",
      "3 0.45241908515871676 [3, 2, 12, 14, 15, 18, 19, 20, 30, 35, 36, 38, 40, 42, 45, 47, 48, 49, 56, 58, 60, 62, 65, 71, 74, 81, 87, 88, 94, 96, 99, 106, 109, 112, 113]\n"
     ]
    }
   ],
   "source": [
    "responses = [[6, 8], [2, 5], [1, 7], [3, 4]]\n",
    "logr_models = [{}]*len(responses)\n",
    "data_train_current = data_train.copy()\n",
    "i = 0\n",
    "for response in responses:\n",
    "    m_train = data_train_current.copy()\n",
    "    if response != [3,4]:\n",
    "        m_train[\"Response\"] = m_train[\"Response\"].apply(lambda x:0 if x not in response else x)\n",
    "    columns_opt, kappa_score_opt = find_opt_columns(m_train)\n",
    "    print (i, kappa_score_opt, columns_opt)\n",
    "    logr_models[i] = {\n",
    "        \"model\": regression_model(columns_opt, m_train),\n",
    "        \"columns\": columns_opt\n",
    "    }\n",
    "    if response != [3,4]:\n",
    "        data_train_current = data_train_current[~data_train_current[\"Response\"].isin(response)]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание данных и оценка модели\n",
    "Последовательно считаем предсказания для каждой классификации. После этого объединяем предсказание по иерархии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logr_hierarchy (x):\n",
    "    for response in range(0, len(responses)):\n",
    "        if x[\"target\" + str(response)] > 0:\n",
    "            x[\"target\"] = x[\"target\" + str(response)]\n",
    "            break;\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for response in range(0, len(responses)):\n",
    "    model = logr_models[response][\"model\"]\n",
    "    columns_opt = logr_models[response][\"columns\"]\n",
    "    x = pd.DataFrame(data_test, columns=columns_opt)\n",
    "    data_test[\"target\" + str(response)] = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "34689 -0.630538 -1.444237 -2.056662  0.154055  0.611857 -0.169414 -1.159587   \n",
      "23615 -0.160284  0.516280  0.365036 -0.471212 -1.634368 -0.169414  0.862391   \n",
      "48438 -0.042377  0.266282  1.424839 -0.187544 -1.634368 -0.169414  0.862391   \n",
      "46619 -1.805488 -1.444237  0.365036 -1.613872 -1.634368 -0.169414  0.862391   \n",
      "4781   0.072787  1.246540  1.122746 -0.607052  0.611857 -0.169414  0.862391   \n",
      "\n",
      "              7         8         9  ...       114       115       116  \\\n",
      "34689  1.101046 -1.156735  1.130555  ...  1.604350 -0.216001 -0.128866   \n",
      "23615 -1.013721  0.870987 -0.928723  ... -0.623305 -0.216001 -0.128866   \n",
      "48438 -1.013721  0.861569 -0.928723  ... -0.623305 -0.216001 -0.128866   \n",
      "46619 -1.013721  0.861569 -0.928723  ... -0.623305 -0.216001 -0.128866   \n",
      "4781  -1.013721  0.861099 -0.928723  ... -0.623305 -0.216001 -0.128866   \n",
      "\n",
      "            117  Response  target0  target1  target2  target3  target  \n",
      "34689 -0.142142       8.0      0.0      0.0      0.0      4.0     4.0  \n",
      "23615 -0.142142       8.0      8.0      0.0      7.0      4.0     8.0  \n",
      "48438 -0.142142       1.0      0.0      0.0      7.0      4.0     7.0  \n",
      "46619 -0.142142       8.0      8.0      0.0      7.0      4.0     8.0  \n",
      "4781  -0.142142       6.0      8.0      0.0      7.0      4.0     8.0  \n",
      "\n",
      "[5 rows x 124 columns]\n"
     ]
    }
   ],
   "source": [
    "data_test = data_test.apply(logr_hierarchy, axis=1,\n",
    "                            result_type=\"expand\")\n",
    "print (data_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация дает 0.192, kNN(100) - 0.3, простая лог. регрессия - 0.512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия, 4 уровня: 0.48\n"
     ]
    }
   ],
   "source": [
    "print (\"Логистическая регрессия, 4 уровня:\",\n",
    "      round(cohen_kappa_score(data_test[\"target\"],\n",
    "                data_test[\"Response\"], weights=\"quadratic\"), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица неточностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 436  344   27   12  202  426  139  148]\n",
      " [ 157  228    5    2   78   68    8    2]\n",
      " [  37   46   66   33   82  181   23    4]\n",
      " [  65   74   62  151   31  364   35   63]\n",
      " [  77  142   10    0  210   66   23   12]\n",
      " [  14   14    2   13    9   93   13   25]\n",
      " [ 224  297   22   14  368  700  837  485]\n",
      " [ 226  189    8   36  148  386  493 3122]]\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(data_test[\"target\"],\n",
    "                data_test[\"Response\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
