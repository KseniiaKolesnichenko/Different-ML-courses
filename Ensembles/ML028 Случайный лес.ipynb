{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Загрузим данные, приведем их к числовым, заполним пропуски, нормализуем данные и оптимизируем память.\n",
    "\n",
    "Разделите выборку на обучающую/проверочную в соотношении 80/20.\n",
    "\n",
    "Построим параллельный ансамбль (бэггинг) решающих деревьев, используя случайный лес.\n",
    "\n",
    "Проведем предсказание и проверим качество через каппа-метрику.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/prudential/train.csv.gz\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/prudential-life-insurance-assessment/\n",
    "\n",
    "© ITtensive, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 128 entries, Id to Response\n",
      "dtypes: float64(18), int64(109), object(1)\n",
      "memory usage: 58.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://video.ittensive.com/machine-learning/prudential/train.csv.gz\")\n",
    "print (data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Product_Info_2_1\"] = data[\"Product_Info_2\"].str.slice(0, 1)\n",
    "data[\"Product_Info_2_2\"] = pd.to_numeric(data[\"Product_Info_2\"].str.slice(1, 2))\n",
    "data.drop(labels=[\"Product_Info_2\"], axis=1, inplace=True)\n",
    "for l in data[\"Product_Info_2_1\"].unique():\n",
    "    data[\"Product_Info_2_1\" + l] = data[\"Product_Info_2_1\"].isin([l]).astype(\"int8\")\n",
    "data.drop(labels=[\"Product_Info_2_1\"], axis=1, inplace=True)\n",
    "data.fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Набор столбцов для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wt', 'Ht', 'Ins_Age', 'BMI', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_5', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', 'Medical_Keyword_1', 'Medical_Keyword_2', 'Medical_Keyword_3', 'Medical_Keyword_4', 'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7', 'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10', 'Medical_Keyword_11', 'Medical_Keyword_12', 'Medical_Keyword_13', 'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16', 'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19', 'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22', 'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25', 'Medical_Keyword_26', 'Medical_Keyword_27', 'Medical_Keyword_28', 'Medical_Keyword_29', 'Medical_Keyword_30', 'Medical_Keyword_31', 'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_34', 'Medical_Keyword_35', 'Medical_Keyword_36', 'Medical_Keyword_37', 'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40', 'Medical_Keyword_41', 'Medical_Keyword_42', 'Medical_Keyword_43', 'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46', 'Medical_Keyword_47', 'Medical_Keyword_48', 'Family_Hist_1', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5', 'Medical_History_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', 'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_15', 'Medical_History_16', 'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_24', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', 'Medical_History_31', 'Medical_History_32', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', 'Medical_History_40', 'Medical_History_41', 'Product_Info_1', 'Product_Info_3', 'Product_Info_4', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7', 'Product_Info_2_2', 'Product_Info_2_1D', 'Product_Info_2_1A', 'Product_Info_2_1E', 'Product_Info_2_1C', 'Product_Info_2_1B']\n"
     ]
    }
   ],
   "source": [
    "columns_groups = [\"Insurance_History\", \"InsurеdInfo\", \"Medical_Keyword\",\n",
    "                  \"Family_Hist\", \"Medical_History\", \"Product_Info\"]\n",
    "columns = [\"Wt\", \"Ht\", \"Ins_Age\", \"BMI\"]\n",
    "for cg in columns_groups:\n",
    "    columns.extend(data.columns[data.columns.str.startswith(cg)])\n",
    "print (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "data_transformed = pd.DataFrame(scaler.fit_transform(pd.DataFrame(data,\n",
    "                                                     columns=columns)))\n",
    "columns_transformed = data_transformed.columns\n",
    "data_transformed[\"Response\"] = data[\"Response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage (df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if str(col_type)[:5] == \"float\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo(\"f2\").min and c_max < np.finfo(\"f2\").max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif c_min > np.finfo(\"f4\").min and c_max < np.finfo(\"f4\").max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "        elif str(col_type)[:3] == \"int\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo(\"i1\").min and c_max < np.iinfo(\"i1\").max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo(\"i2\").min and c_max < np.iinfo(\"i2\").max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo(\"i4\").min and c_max < np.iinfo(\"i4\").max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo(\"i8\").min and c_max < np.iinfo(\"i8\").max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Потребление памяти меньше на', round(start_mem - end_mem, 2), 'Мб (минус', round(100 * (start_mem - end_mem) / start_mem, 1), '%)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 40.49 Мб (минус 75.1 %)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 119 entries, 0 to Response\n",
      "dtypes: float16(118), int8(1)\n",
      "memory usage: 13.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_transformed = reduce_mem_usage(data_transformed)\n",
    "print (data_transformed.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных\n",
    "Преобразуем выборки в отдельные наборы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "49512 -0.513672 -0.710449 -0.391602 -0.178589 -1.634766 -0.169434  0.862305   \n",
      "4432  -0.866211 -0.220581 -1.981445 -0.935547  0.611816 -0.169434 -1.159180   \n",
      "6493  -1.688477 -1.445312 -0.845703 -1.436523 -1.634766 -0.169434  0.862305   \n",
      "42525 -1.359375 -0.465576  0.213989 -1.457031  0.611816  5.902344  0.862305   \n",
      "12794  0.308838 -0.220581 -0.164429  0.578613  0.611816 -0.169434 -1.159180   \n",
      "\n",
      "              7         8         9  ...       109       110       111  \\\n",
      "49512 -1.013672  0.864258 -0.928711  ... -0.083679  0.441650 -0.149292   \n",
      "4432   1.100586 -1.156250  1.130859  ... -0.083679  0.441650 -0.149292   \n",
      "6493  -1.013672  0.863770 -0.928711  ... -0.083679 -2.263672 -0.149292   \n",
      "42525  0.043671  0.861328 -0.928711  ... -0.083679  0.441650 -0.149292   \n",
      "12794  1.100586 -1.156250  1.130859  ... -0.083679  0.441650 -0.149292   \n",
      "\n",
      "            112       113       114       115       116       117  Response  \n",
      "49512 -0.666992 -1.332031 -0.623535 -0.215942 -0.128906  7.035156         8  \n",
      "4432   0.733398 -1.332031  1.604492 -0.215942 -0.128906 -0.142090         8  \n",
      "6493   0.266846  0.750977 -0.623535 -0.215942 -0.128906 -0.142090         7  \n",
      "42525  0.266846  0.750977 -0.623535 -0.215942 -0.128906 -0.142090         6  \n",
      "12794 -0.200073  0.750977 -0.623535 -0.215942 -0.128906 -0.142090         6  \n",
      "\n",
      "[5 rows x 119 columns]\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data_transformed,\n",
    "                                         test_size=0.2)\n",
    "data_train = pd.DataFrame(data_train)\n",
    "data_test = pd.DataFrame(data_test)\n",
    "print (data_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перекрестная проверка случайного леса\n",
    "Каждое дерево (по умолчанию, их 100) строится на своей части выборки со своим набором параметров (max_features). Решение принимается путем голосования деревьев.\n",
    "\n",
    "Например, 10 деревьев для 1 строки (кортежа) исходных параметров дали следующие классы и их вероятности:\n",
    "\n",
    "{1:0.5, 1:0.8, 2:0.9, 3:0.7, 5:0.5, 1:0.4, 2:0.5, 6:0.5, 3:0.4, 1:0.95}\n",
    "\n",
    "По итогам голосования выбирается самый популярный класс, это 1 в данном случае.\n",
    "\n",
    "Если в случайном лесу слишком много деревьев, то точность предсказания будет меньше, чем у одного, полностью обученного дерева. Число деревьев (estimators) должно соответствовать количеству классов в предсказании (class), размеру выборки (N) и числу разбиений (fold). Примерная формула:\n",
    "estimators = N / (20-100) / fold / class\n",
    "\n",
    "В нашем случае, N=60000, fold=5, class=8 => estimators=15...75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(data_train, columns=columns_transformed)\n",
    "model = RandomForestClassifier(random_state=17, n_estimators=77,\n",
    "                max_depth=17, max_features=27, min_samples_leaf=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Диапазон тестирования параметров модели ограничен только вычислительной мощностью. Для проверки модели имеет смысл провести индивидуальные перекрестные проверки для каждого параметра в отдельности, затем в итоговой проверке перепроверить самые лучшие найденные параметры с отклонением +/-10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=2)]: Done  80 out of  80 | elapsed: 16.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=17,\n",
       "                                              max_features=27,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=30,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=77, n_jobs=None,\n",
       "                                              oob_score=False, random_state=17,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=2,\n",
       "             param_grid={'max_depth': range(15, 17),\n",
       "                         'max_features': range(26, 28),\n",
       "                         'min_samples_leaf': range(19, 21),\n",
       "                         'n_estimators': range(75, 77)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(cohen_kappa_score), verbose=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_params = {\n",
    "    'max_depth': range(15,17),\n",
    "    'max_features': range(26,28),\n",
    "    'n_estimators': range(75,77),\n",
    "    'min_samples_leaf': range(19,21)\n",
    "}\n",
    "tree_grid = GridSearchCV(model, tree_params, cv=5, n_jobs=2,\n",
    "            verbose=True, scoring=make_scorer(cohen_kappa_score))\n",
    "tree_grid.fit(x, data_train[\"Response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем самые оптимальные параметры и построим итоговую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15, 'max_features': 27, 'min_samples_leaf': 19, 'n_estimators': 75}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=15, max_features=27,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=19, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=75,\n",
       "                       n_jobs=None, oob_score=False, random_state=17, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (tree_grid.best_params_)\n",
    "model = RandomForestClassifier(random_state=17,\n",
    "        min_samples_leaf=tree_grid.best_params_['min_samples_leaf'],\n",
    "        max_features=tree_grid.best_params_['max_features'],\n",
    "        max_depth=tree_grid.best_params_['max_depth'],\n",
    "        n_estimators=tree_grid.best_params_['n_estimators'])\n",
    "model.fit(x, data_train[\"Response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание данных и оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.DataFrame(data_test, columns=columns_transformed)\n",
    "data_test[\"target\"] = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация дает 0.192, kNN(100) - 0.3, лог. регрессия - 0.512/0.496, SVM - 0.95, реш. дерево - 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Случайный лес: 0.487\n"
     ]
    }
   ],
   "source": [
    "print (\"Случайный лес:\",\n",
    "      round(cohen_kappa_score(data_test[\"target\"],\n",
    "            data_test[\"Response\"], weights=\"quadratic\"), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица неточностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Случайный лес\n",
      " [[ 115   63   11   18   12   32    8    1]\n",
      " [ 192  303   12    0   68   66    6    4]\n",
      " [  20   20   52   10    1    2    0    0]\n",
      " [  42   38   51  189    0    2    0    3]\n",
      " [  95  161   22    0  581   92   14    6]\n",
      " [ 321  272   25   33  219 1234  343  133]\n",
      " [ 148  132    2    8   56  270  614  132]\n",
      " [ 324  308    7   42  122  524  648 3648]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Случайный лес\\n\",\n",
    "      confusion_matrix(data_test[\"target\"], data_test[\"Response\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
